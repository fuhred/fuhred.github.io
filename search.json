[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Portfolio",
    "section": "",
    "text": "Research: Careless Responders\n\n\n\nresearch design\n\n\nanalysis\n\n\nshiny\n\n\ndataviz\n\n\ncode\n\n\n\n\n\n\n\nNov 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch: Free Speech and Inclusion\n\n\n\nresearch design\n\n\nanalysis\n\n\ndataviz\n\n\n\n\n\n\n\nSep 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch: IDEA Climate Survey 2022-2023\n\n\n\nresearch design\n\n\nanalysis\n\n\ndataviz\n\n\n\n\n\n\n\nJul 2023\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\nDataviz: “A Recipe for Redemption” Research Poster\n\n\n\nanalysis\n\n\ndataviz\n\n\n\n\n\n\n\nFeb 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial: Dumbbell Chart with a Gap Column\n\n\n\ndataviz\n\n\ntutorial\n\n\ncode\n\n\n\n\n\n\n\nMar 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial: Affective Polarization\n\n\n\nanalysis\n\n\ndataviz\n\n\ntutorial\n\n\ncode\n\n\n\n\n\n\n\nMar 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiracial Counties in the US\n\n\n\nanalysis\n\n\ndataviz\n\n\nspatial\n\n\n\n\n\n\n\nAug 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShinyApp: Pseudonym Generator\n\n\n\nshiny\n\n\n\n\n\n\n\nJun 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataviz: “Who Are Empathic People?” Research Poster\n\n\n\nanalysis\n\n\ndataviz\n\n\n\n\n\n\n\nFeb 2020\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/pseudonym-generator/pseudonym-generator.html",
    "href": "posts/pseudonym-generator/pseudonym-generator.html",
    "title": "ShinyApp: Pseudonym Generator",
    "section": "",
    "text": "Preview Image\nLaunch the ShinyApp"
  },
  {
    "objectID": "posts/pseudonym-generator/pseudonym-generator.html#objective",
    "href": "posts/pseudonym-generator/pseudonym-generator.html#objective",
    "title": "ShinyApp: Pseudonym Generator",
    "section": "Objective:",
    "text": "Objective:\nDevelop a Shiny app-based pseudonym generator that useshistorical U.S. Social Security data to generate names based on gender and year, aiding in anonymizing quotes while reflecting the demographic details of participants."
  },
  {
    "objectID": "posts/pseudonym-generator/pseudonym-generator.html#approach",
    "href": "posts/pseudonym-generator/pseudonym-generator.html#approach",
    "title": "ShinyApp: Pseudonym Generator",
    "section": "Approach",
    "text": "Approach\nImplemented a user-friendly interface in Shiny where users can specify the first name, age, and gender preference for pseudonyms. The app filters names starting with the same letter as the input and selects those popular in the user’s birth year, providing a personalized yet anonymous identifier."
  },
  {
    "objectID": "posts/pseudonym-generator/pseudonym-generator.html#tools-used",
    "href": "posts/pseudonym-generator/pseudonym-generator.html#tools-used",
    "title": "ShinyApp: Pseudonym Generator",
    "section": "Tools Used",
    "text": "Tools Used\nUsethe Shiny package in R for the web app framework. The babynames package provided access to a comprehensive dataset from the U.S. Social Security Administration, covering names from 1880 to 2017."
  },
  {
    "objectID": "posts/idea-climatesurvey-2022-2023/ideaclimatesurvey2022-2023.html#objective",
    "href": "posts/idea-climatesurvey-2022-2023/ideaclimatesurvey2022-2023.html#objective",
    "title": "Research: IDEA Climate Survey 2022-2023",
    "section": "Objective",
    "text": "Objective\nTo evaluate the climate of inclusion, diversity, equity, and access (IDEA) among undergraduate psychology students at the University of Toronto Mississauga. The survey aimed to identify key areas of strength and improvement by gathering insights into students’ experiences and perceptions regarding these dimensions."
  },
  {
    "objectID": "posts/idea-climatesurvey-2022-2023/ideaclimatesurvey2022-2023.html#approach",
    "href": "posts/idea-climatesurvey-2022-2023/ideaclimatesurvey2022-2023.html#approach",
    "title": "Research: IDEA Climate Survey 2022-2023",
    "section": "Approach",
    "text": "Approach\nThe project involved the design and execution of a detailed survey distributed over several months. As a key project administrator and methodologist, I coordinated the efforts of faculty, postdocs, graduate, and undergraduate students, ensuring rigorous data analysis and results presentation. We crafted the survey to capture a wide range of demographic information and students’ personal experiences with IDEA-related issues. Analysis involved quantitative and qualitative methods to thoroughly examine the data collected."
  },
  {
    "objectID": "posts/idea-climatesurvey-2022-2023/ideaclimatesurvey2022-2023.html#tools-used",
    "href": "posts/idea-climatesurvey-2022-2023/ideaclimatesurvey2022-2023.html#tools-used",
    "title": "Research: IDEA Climate Survey 2022-2023",
    "section": "Tools Used",
    "text": "Tools Used\nThe survey was developed and analyzed using a combination of statistical software (R, SPSS, Excel) and qualitative analysis tools. Data curation, formal analysis, and visualization were performed using advanced statistical software packages. Contributions included data analysis, writing, and clear visualization of findings for report preparation.\nRead the report"
  },
  {
    "objectID": "posts/empathic-people-poster/empathic-people-poster.html#objective",
    "href": "posts/empathic-people-poster/empathic-people-poster.html#objective",
    "title": "Dataviz: “Who Are Empathic People?” Research Poster",
    "section": "Objective",
    "text": "Objective\nPresent the findings of a research project on various measures of empathy and their correlates, allowing for an intuitive visual comparison of how different empathies are correlated with key personality traits. Format was a 48” x 36” poster that was presented at the 2020 Annual Conference for the Society of Personality and Social Psychology."
  },
  {
    "objectID": "posts/empathic-people-poster/empathic-people-poster.html#approach",
    "href": "posts/empathic-people-poster/empathic-people-poster.html#approach",
    "title": "Dataviz: “Who Are Empathic People?” Research Poster",
    "section": "Approach",
    "text": "Approach\nEmployed a multi-dimensional visualization strategy using radar charts to depict the relationship between various empathy definitions and personality traits. This approach helped in highlighting the nuances between different scholarly interpretations of empathy and their psychological profiles."
  },
  {
    "objectID": "posts/empathic-people-poster/empathic-people-poster.html#tools-used",
    "href": "posts/empathic-people-poster/empathic-people-poster.html#tools-used",
    "title": "Dataviz: “Who Are Empathic People?” Research Poster",
    "section": "Tools Used",
    "text": "Tools Used\nR and ggplot (using custom functions) were used to create detailed radar charts. This allowed for a clear, visual summary of complex multi-trait data, making the information accessible and engaging for viewers. Final design was created in PowerPoint."
  },
  {
    "objectID": "posts/careless-responders/careless-responders.html",
    "href": "posts/careless-responders/careless-responders.html",
    "title": "Research: Careless Responders",
    "section": "",
    "text": "This research examines several aspects of careless responding—responding that is not attentive to the content of the questions or items being administered.\nKey takeaways\n\nOn the whole, careless responding inflates effects rather than weakens them. Most researchers incorrectly assume the opposite, and in a survey of editors of leading psychology journals, we find that even these seasoned experts have incorrect intuitions.\nPublished peer-reviewed studies in high-impact journals often insufficiently screen for careless responding.\nWe provide an interactive web tool (a Shiny app) to explore and demonstrate careless responding examples in real time.\n\nI played a key role in this project, overseeing or contributing to study design, analysis, data visualization, tool development, writing, and editing. Here, I showcase two contributions: the Shiny app and an alluvial data visualization."
  },
  {
    "objectID": "posts/careless-responders/careless-responders.html#overview",
    "href": "posts/careless-responders/careless-responders.html#overview",
    "title": "Research: Careless Responders",
    "section": "",
    "text": "This research examines several aspects of careless responding—responding that is not attentive to the content of the questions or items being administered.\nKey takeaways\n\nOn the whole, careless responding inflates effects rather than weakens them. Most researchers incorrectly assume the opposite, and in a survey of editors of leading psychology journals, we find that even these seasoned experts have incorrect intuitions.\nPublished peer-reviewed studies in high-impact journals often insufficiently screen for careless responding.\nWe provide an interactive web tool (a Shiny app) to explore and demonstrate careless responding examples in real time.\n\nI played a key role in this project, overseeing or contributing to study design, analysis, data visualization, tool development, writing, and editing. Here, I showcase two contributions: the Shiny app and an alluvial data visualization."
  },
  {
    "objectID": "posts/careless-responders/careless-responders.html#shiny-app",
    "href": "posts/careless-responders/careless-responders.html#shiny-app",
    "title": "Research: Careless Responders",
    "section": "Shiny app",
    "text": "Shiny app\n\n\n\n\n\nWhile we write in the article on the effects of careless responding, this tool vividly demonstrates how careless responses can artificially inflate statistical correlations, providing an engaging, hands-on learning experience. To program this, I used R/Shiny/ggplot2, and the full code is available on Github. Click on button to launch.\n\nLaunch the Shiny app"
  },
  {
    "objectID": "posts/careless-responders/careless-responders.html#alluvial-figure",
    "href": "posts/careless-responders/careless-responders.html#alluvial-figure",
    "title": "Research: Careless Responders",
    "section": "Alluvial figure",
    "text": "Alluvial figure\n\n\n\n\n\nMy goal was to highlight the gap between the frequencies of good practices (stringent screening) and poor practices (less stringent or no screening). Alluvial plots are visualizations that are striking and beautiful. However, they are also often unclear, like visual puzzles that end up not communicating what is intended.\nHere, I designed a custom color palette to highlight differences, with brighter, more vivid colors for good careless responding practices. The colors emphasize that only a minority of published studies in high impact journals used sufficiently stringent screening. To make this, I used RAWGraphs to make the base figure and the vector illustrator program InkScape for color gradients and text editing."
  },
  {
    "objectID": "posts/careless-responders/careless-responders.html#the-peer-reviewed-article",
    "href": "posts/careless-responders/careless-responders.html#the-peer-reviewed-article",
    "title": "Research: Careless Responders",
    "section": "The Peer-Reviewed Article",
    "text": "The Peer-Reviewed Article\nFor a deeper exploration of our findings and methodologies, the peer-reviewed article can be accessed in the journal Advances in Methods and Practices in Psychological Science:\nStosic, M. D., Murphy, B. A., Duong, F., Fultz, A. A., Harvey, S. E., & Bernieri, F. (2024). Careless Responding: Why Many Findings Are Spurious or Spuriously Inflated. Advances in Methods and Practices in Psychological Science, 7(1), 25152459241231581.\n\nAbstract: Contrary to long-standing conventional wisdom, failing to exclude data from carelessly responding participants on questionnaires or behavioral tasks will frequently result in false-positive or spuriously inflated findings. Despite prior publications demonstrating this disturbing statistical confound, it continues to be widely underappreciated by most psychologists, including highly experienced journal editors. In this article, we aim to comprehensively explain and demonstrate the severity and widespread prevalence of careless responding’s (CR) inflationary effects in psychological research. We first describe when and why one can expect to observe the inflationary effect of unremoved CR data in a manner accessible to early graduate or advanced undergraduate students. To this end, we provide an online simulator tool and instructional videos for use in classrooms. We then illustrate realistic magnitudes of the severity of unremoved CR data by presenting novel reanalyses of data sets from three high-profile articles: We found that many of their published effects would have been meaningfully, sometimes dramatically, inflated if they had not rigorously screened out CR data. To demonstrate the frequency with which researchers fail to adequately screen for CR, we then conduct a systematic review of CR screening procedures in studies using paid online samples (e.g., MTurk) published across two prominent psychological-science journals. These findings suggest that most researchers either did not conduct any kind of CR screening or conducted only bare minimal screening. To help researchers avoid publishing spuriously inflated findings, we summarize best practices to help mitigate the threats of CR data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fred Duong, Ph.D.",
    "section": "",
    "text": "I am a mixed-methods researcher with a passion for delivering clear insights from complex research. I am skilled in advanced analytics, statistical programming, and data visualization. My favorite projects start with investigating messy constructs and end with compelling, data-driven narratives and beautiful visuals.\nI am an expert in emotions, morality, and political psychology, though I have wide-ranging interests that I investigate using social and personality psychology. My work spans nonprofit and academic sectors. I am currently a Research Fellow at Constructive Dialogue Institute, a Research Fellow at More in Common, and a Postdoctoral Fellow at University of Toronto Mississauga. For a sample of my research, programming and data visualization, check out my portfolio.\nI have a Ph.D. in psychology from Northeastern University, a M.A. in psychology from New York University, and a B.A. in sociology from University of North Texas."
  },
  {
    "objectID": "posts/affective-polarization/affectivepolarization.html",
    "href": "posts/affective-polarization/affectivepolarization.html",
    "title": "Tutorial: Affective Polarization",
    "section": "",
    "text": "I wanted to recreate the figures from The Origins and Consequences of Affective Polarization in the United States (Iyengar et al., 2019) and Political Sectarianism in America (Finkel et al., 2020) shown below. They use American National Election Studies data to show how Affective Polarization has changed over time. This tutorial will not reproduce the figures exactly, but it will at least give you the base figure to work from to modify for your own purposes. This code uses tidy principles.\nIyengar et al., (2019)\nFinkel et al., (2020)"
  },
  {
    "objectID": "posts/affective-polarization/affectivepolarization.html#simple-plot",
    "href": "posts/affective-polarization/affectivepolarization.html#simple-plot",
    "title": "Tutorial: Affective Polarization",
    "section": "Simple plot",
    "text": "Simple plot\n\ndf_p %&gt;% \n  ggplot(aes(x=VCF0004, y=Warmth, color=feeling)) +\n  geom_point() +\n  geom_line()"
  },
  {
    "objectID": "posts/affective-polarization/affectivepolarization.html#simple-plot-2",
    "href": "posts/affective-polarization/affectivepolarization.html#simple-plot-2",
    "title": "Tutorial: Affective Polarization",
    "section": "Simple plot 2",
    "text": "Simple plot 2\nNot bad. Here’s the final version I ended up exporting as SVG so I can further play around with aesthetics in PowerPoint.\n\ndf_p %&gt;% \n  mutate(feeling=recode(feeling,\n                        inparty_feeling=\"Inparty Feeling\",\n                        outparty_feeling=\"Outparty Feeling\",\n                        )) %&gt;% \n  ggplot(aes(x=VCF0004, y=Warmth, color=feeling)) +\n  \n  geom_ribbon(\n    data=. %&gt;% group_by(VCF0004) %&gt;% rstatix::get_summary_stats(Warmth),\n    aes(ymin=min,ymax=max, y=mean, color=NULL),\n    fill=\"gray96\", show.legend = F)+  \n  \n  geom_hline(yintercept=50, color=\"gray\", linetype=\"dashed\")+\n  \n  geom_point(size=2.5) +\n  geom_line(size=1, show.legend = F) +\n\n  scale_x_continuous(breaks=seq(1980, 2020, by=4)) +\n  scale_y_continuous(limits=c(0,100),\n                     labels = paste0(seq(0, 100, by=25), \"°\")\n                     ) +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank(),\n        panel.grid.major = element_blank(),\n        axis.title.x = element_blank(),\n        axis.text.x = element_text(angle=45, hjust=1),\n        legend.title = element_blank()) +\n  labs(x=\"Election year\", y=\"Feeling thermometer rating\",\n       title=\"Affective Polarization Over Time Using ANES Data\")"
  },
  {
    "objectID": "posts/affective-polarization/affectivepolarization.html#affective-polarization",
    "href": "posts/affective-polarization/affectivepolarization.html#affective-polarization",
    "title": "Tutorial: Affective Polarization",
    "section": "Affective Polarization",
    "text": "Affective Polarization\nLet’s add an affective polarization columns. Iyengar et al. (2019) calcualtes this as the difference between the feelings, whereas Finkel et al. (2020) calculates this as the difference between inparty love (inparty feeling - 50) and outparty hate (50 - outparty feeling). I’ll do both.\n\n# this is our earlier code, but i am re-running it because i reshaped it to be long\n# and we want wide format to do our calculations\ndf_p=\ndf %&gt;% \n  select(VCF0004, PID, inparty_feeling, outparty_feeling) %&gt;% \n  group_by(VCF0004) %&gt;% \n  summarise(inparty_feeling= mean(inparty_feeling,  na.rm=T),\n            outparty_feeling=mean(outparty_feeling, na.rm=T)\n            ) %&gt;% \n\n  #new code\n  rowwise() %&gt;% \n  mutate(aff_polar_iyengar=inparty_feeling-outparty_feeling,\n         aff_polar_finkel = (inparty_feeling-50)-(50-outparty_feeling)\n         )\n\n\ndf_p %&gt;% head\n\n# A tibble: 6 × 5\n# Rowwise: \n  VCF0004 inparty_feeling outparty_feeling aff_polar_iyengar aff_polar_finkel\n    &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;\n1    1978            73.9             47.0              26.9             20.8\n2    1980            75.0             45.6              29.4             20.6\n3    1982            76.2             43.4              32.8             19.6\n4    1984            76.8             44.9              31.9             21.7\n5    1986            76.4             45.1              31.3             21.5\n6    1988            77.6             44.0              33.7             21.6\n\n\nLet’s see if we can’t reproduce each figure more closely. In my experience the fine details require a lot of extra code, so this will only roughly approximate what the figures show.\nHere’s the Iyengar reproduction."
  },
  {
    "objectID": "posts/affective-polarization/affectivepolarization.html#iyengar-et-al.-2019",
    "href": "posts/affective-polarization/affectivepolarization.html#iyengar-et-al.-2019",
    "title": "Tutorial: Affective Polarization",
    "section": "Iyengar et al. (2019)",
    "text": "Iyengar et al. (2019)\n\ndf_p %&gt;% \n  \n  select(-aff_polar_finkel) %&gt;%  #we just want iyengar's aff polar\n  \n  #reshape\n  pivot_longer(-VCF0004, names_to=\"feeling\", values_to=\"Warmth\") %&gt;% \n  \n  \n  mutate(feeling=recode(feeling,\n                        inparty_feeling=\"In-party feeling\",\n                        outparty_feeling=\"Out-party feeling\",\n                        aff_polar_iyengar=\"Affective polarization\"\n                        ),\n         feeling=factor(feeling, levels=c(\"In-party feeling\",   #setting levels just so ordering colors/shapes\n                                          \"Out-party feeling\",  #is more intuitive. otherwise, ggplot orders this\n                                          \"Affective polarization\" #alphabetically\n                                          ))\n         ) %&gt;%   \n  \n  \n  #plot\n  ggplot(aes(x=VCF0004, y=Warmth, color=feeling)) +\n  geom_hline(yintercept=50, color=\"gray\", linetype=\"dashed\")+\n  geom_point(aes(shape=feeling, fill=feeling), size=2) +\n  geom_line(aes(linetype=feeling)) +\n  scale_x_continuous(breaks=seq(1980, 2020, by=4)) +\n  scale_y_continuous(limits=c(0,100),\n                     labels = paste0(seq(0, 100, by=25), \"°\")\n                     ) +  \n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        # axis.text.x = element_text(angle=45, hjust=1),\n        legend.title = element_blank(),\n        axis.ticks.length=unit(-0.15, \"cm\") #flip this ticks inside\n        ) +\n  labs(x=\"Election year\", y=\"Feeling thermometer rating\",\n       title=\"Affective Polarization - Iyengar et al. (2019) reproduction\") +\n  \n  #use Iyengar's colors. You can use a color picker to sample colors from images and get the hex code\n  #I use Color Cop for Windows (free)\n  scale_color_manual(values=c(\"#1D9E74\", #green\n                              \"#AD6FAE\", #purple\n                              \"#6C6D70\"  #gray\n                              )) +\n  scale_fill_manual(values=c(\"#1D9E74\", #green\n                              \"#AD6FAE\", #purple\n                              \"#6C6D70\"  #gray\n                              )) +\n  \n  scale_shape_manual(values=c(19, #circle\n                              15, #square\n                              23  #diamond\n                              )) +\n  scale_linetype_manual(values=c(\"dotted\",\"dashed\",\"solid\"))\n\n\n\n\n\n\n\n  #Note: it seems like making a gradient background is not straightforward in ggplot\n  #I would just export this as SVG and then make a gradient in another program"
  },
  {
    "objectID": "posts/affective-polarization/affectivepolarization.html#finkel-et-al.-2020",
    "href": "posts/affective-polarization/affectivepolarization.html#finkel-et-al.-2020",
    "title": "Tutorial: Affective Polarization",
    "section": "Finkel et al. (2020)",
    "text": "Finkel et al. (2020)\nThis figure is interesting because it’s actually two figures: feeling thermometers on top and affective polarization on bottom.\n\n\nTop figure\n\ndf_p %&gt;% \n  \n  select(-aff_polar_iyengar, -aff_polar_finkel) %&gt;%  #we just want iyengar's aff polar\n  \n  #reshape\n  pivot_longer(-VCF0004, names_to=\"feeling\", values_to=\"Warmth\") %&gt;% \n  \n  \n  mutate(feeling=recode(feeling,\n                        inparty_feeling=\"In-party feeling\",\n                        outparty_feeling=\"Out-party feeling\",\n                        aff_polar_finkel=\"Affective polarization\"\n                        ),\n         feeling=factor(feeling, levels=c(\"In-party feeling\",   #setting levels just so ordering colors/shapes\n                                          \"Out-party feeling\",  #is more intuitive. otherwise, ggplot orders this\n                                          \"Affective polarization\" #alphabetically\n                                          ))\n         ) %&gt;%   \n  \n  \n  #plot\n  ggplot(aes(x=VCF0004, y=Warmth, color=feeling)) +\n  geom_hline(yintercept=50, color=\"black\")+\n  geom_smooth(aes(group=feeling,color=NULL, linetype=feeling),\n              method=lm, se=F, color=\"black\", size=.75)+\n  geom_point(aes(shape=feeling, fill=feeling), size=2) +\n  # geom_line(aes(linetype=feeling)) +\n  scale_x_continuous(breaks=seq(1980, 2020, by=4)\n                     ) +\n  scale_y_continuous(limits=c(0,100),\n                     labels = paste0(seq(0, 100, by=25), \"°\")\n                     ) +  \n  theme_classic() +\n  theme(panel.grid = element_blank(),\n        legend.title = element_blank(),\n        panel.border = element_blank()\n        ) +\n  labs(x=\"Election year\", y=\"Feeling thermometer ratings\",\n       title=\"Affective Polarization - Finkel et al. (2020) reproduction\") +\n  \n  #use Iyengar's colors. You can use a color picker to sample colors from images and get the hex code\n  #I use Color Cop for Windows (free)\n  scale_color_manual(values=c(\"#D8631B\", \n                              \"#00AEAE\", #purple\n                              \"#6C6D70\"  #gray\n                              )) +\n  scale_fill_manual(values=c(\"#1D9E74\", #green\n                              \"#AD6FAE\", #purple\n                              \"#6C6D70\"  #gray\n                              )) +\n  \n  scale_shape_manual(values=c(15, #square\n                              17, #circle\n                              \n                              15  #diamond\n                              )) +\n  scale_linetype_manual(values=c(\"solid\",\"dashed\",\"solid\"))\n\n\n\n\n\n\n\n\n\n\nBottom figure\n\ndf_p %&gt;% \n  \n  select(VCF0004, aff_polar_finkel) %&gt;%  #\n  pivot_longer(-VCF0004, names_to=\"feeling\", values_to=\"Warmth\") %&gt;%   #reshape\n  \n  mutate(feeling=recode(feeling,\n                        aff_polar_finkel=\"Affective polarization\"\n                        )) %&gt;%   \n  \n  #plot\n  ggplot(aes(x=VCF0004, y=Warmth)) +\n  geom_hline(yintercept=0, color=\"black\")+\n  geom_line()+\n  geom_point(shape=15, size=2) +\n  scale_x_continuous(breaks=seq(1980, 2020, by=4)) +\n  scale_y_continuous(limits=c(-15, 25),\n                     breaks=seq(-15, 25, by=5),\n                     labels = paste0(seq(-15, 25, by=5), \"°\")\n                     ) +\n  theme_classic() +\n  theme(panel.grid = element_blank(),\n        legend.title = element_blank(),\n        panel.border = element_blank(),\n        axis.title.x = element_blank()\n        ) +\n  labs(x=\"Election year\", y=\"In-party love - Out-party hate\",\n       title=\"Affective Polarization - Finkel et al. (2020)\")"
  },
  {
    "objectID": "posts/dumbbell-with-gap/dumbbell.html",
    "href": "posts/dumbbell-with-gap/dumbbell.html",
    "title": "Tutorial: Dumbbell Chart with a Gap Column",
    "section": "",
    "text": "This tutorial will show you how to create dumbbell charts with gap columns, similar to the charts you might have seen from Pew and YouGov. A Pew dumbbell chart is shown below.\nWe can get pretty close to the chart with ggplot2() (and with a lot more tweaking that we won’t go into here, we could probably exactly recreate the chart!) Here is the final figure that we’ll create.\nBut first, let’s create the basic figure!"
  },
  {
    "objectID": "posts/dumbbell-with-gap/dumbbell.html#data-wrangle",
    "href": "posts/dumbbell-with-gap/dumbbell.html#data-wrangle",
    "title": "Tutorial: Dumbbell Chart with a Gap Column",
    "section": "Data Wrangle",
    "text": "Data Wrangle\n\ndf_long=df %&gt;% \n  pivot_longer(-labels)\n\ndf_long\n\n# A tibble: 14 × 3\n   labels                           name  value\n   &lt;chr&gt;                            &lt;chr&gt; &lt;dbl&gt;\n 1 Spirituality, faith and religion Dem       8\n 2 Spirituality, faith and religion Rep      22\n 3 Freedom and independence         Dem       6\n 4 Freedom and independence         Rep      12\n 5 Hobbies and recreation           Dem      13\n 6 Hobbies and recreation           Rep       7\n 7 Physical and mental health       Dem      13\n 8 Physical and mental health       Rep       9\n 9 COVID-19                         Dem       8\n10 COVID-19                         Rep       5\n11 Pets                             Dem       5\n12 Pets                             Rep       2\n13 Nature and the outdoors          Dem       5\n14 Nature and the outdoors          Rep       3"
  },
  {
    "objectID": "posts/dumbbell-with-gap/dumbbell.html#plot",
    "href": "posts/dumbbell-with-gap/dumbbell.html#plot",
    "title": "Tutorial: Dumbbell Chart with a Gap Column",
    "section": "Plot",
    "text": "Plot\nFrom here, I’ll use geom_line() to create the horizontal line that connects the points on each figure row that represents the gap, and geom_point() to create the dots for each party. I want to set the color aesthetic for geom_point() so that Republicans and Democrats are displayed in different colors.\n\ndf_long %&gt;% \n  ggplot(aes(x=value,y=labels)) +\n  \n  geom_line(linewidth=3.5) + \n  # note that linewidth is a little larger than the point size \n  # so that the line matches the height of the point. why is it \n  # like that? i don't really know  \n  \n  geom_point(aes(color=name), size=3) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.title = element_blank(),\n        panel.grid = element_blank()\n        ) +\n  scale_x_continuous(labels = scales::percent_format(scale = 1))\n\n\n\n\n\n\n\n\nOf course, the colors are wrong. To pull colors from existing figures, I use a free color picker program for Windows called Color Cop. Then I’ll insert the colors in the code."
  },
  {
    "objectID": "posts/dumbbell-with-gap/dumbbell.html#plot-with-colors",
    "href": "posts/dumbbell-with-gap/dumbbell.html#plot-with-colors",
    "title": "Tutorial: Dumbbell Chart with a Gap Column",
    "section": "Plot with colors",
    "text": "Plot with colors\n\ndf_long %&gt;% \n  ggplot(aes(x=value,y=labels)) +\n  geom_line(color=\"#E7E7E7\", linewidth=3.5) + \n  geom_point(aes(color=name), size=3) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.y = element_text(color=\"black\"),\n        axis.text.x = element_text(color=\"#989898\"),\n        axis.title = element_blank(),\n        panel.grid = element_blank()\n        ) +\n  scale_color_manual(values=c(\"#436685\", \"#BF2F24\"))+\n  scale_x_continuous(labels = scales::percent_format(scale = 1))\n\n\n\n\n\n\n\n\nThat’s it! Not a ton of code! But, you’ll notice that this is missing a few key formatting features from the original Pew figure.\n\nThe y-axis is not sorted. By default, ggplot() alphabetizes character vectors that are used for the axes. Then, it displays the y-axis values reverse alphabetized. We can manually sort this however we want, but sorting by descending gaps is common. To do this, we will compute the gaps, and then turn the y-axis labels into a factor so that ggplot() respects the order.\nThere are no text labels. Some dumbbell figures have data callouts to the left and right, and some have them underneath or above the points. When it’s to the left and right, it’s a little complicated to implement. There are two issues: 1) Because Democrats and Republicans might switch orders in terms of which is the higher value, you can’t rely just the categories themselves to decide which is left and right (Democrats won’t always be the lower value, for example); and 2) by default, positioning the data callouts will place them right on top of the points. But we will want to nudge the data callouts either to the left or to the right of the points. To solve this, we will create a variable that assesses the maximum value per label (or minimum) to assign the left and right callouts. Then, we can either use two geom_text()s, with each one using filter() on the data to only show the maximum or not the maximum and using the color aesthetic set to political party, or–more simply–use one geom_text() that uses an if_else() statement to assign that conditions on if the value == the maximum value. I’ll show the latter case.\nThere is no color legend for the points. By default, ggplot will attempt to put a typical legend for your color aesthetic that is placed to the right. You’ll see above I turned this off in theme(). It can be much more readable to place the legend above the actual points themselves, as you see from the Pew figure.\nThere is no gap column. The best way I can figure out how to do this is to create a second ggplot object, and use patchwork to stitch it together with the main plot.\n\nThe complete figure will solve all four issues, but this requires a lot more tweaking. The complete figure will consist of the main dumbbell figure and a gap figure."
  },
  {
    "objectID": "posts/dumbbell-with-gap/dumbbell.html#dumbbell-figure",
    "href": "posts/dumbbell-with-gap/dumbbell.html#dumbbell-figure",
    "title": "Tutorial: Dumbbell Chart with a Gap Column",
    "section": "Dumbbell Figure",
    "text": "Dumbbell Figure\n\nData Wrangle\n\ndf=raw %&gt;% # raw is just the generated data\n  \n  # compute the gap\n  mutate(gap=Rep-Dem) %&gt;% \n  \n  # find the maximum value by label\n  group_by(labels) %&gt;% \n  mutate(max=max(Dem, Rep)) %&gt;% \n  ungroup() %&gt;% \n  \n  # sort the labels by gap value\n  # note that its absolute value of gap\n  mutate(labels=forcats::fct_reorder(labels, abs(gap)))  \n\n# make into long format for easier plotting  \ndf_long=df %&gt;% \n  pivot_longer(\n    c(Dem,Rep)\n  )\n\ndf \n\n# A tibble: 7 × 5\n  labels                             Dem   Rep   gap   max\n  &lt;fct&gt;                            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Spirituality, faith and religion     8    22    14    22\n2 Freedom and independence             6    12     6    12\n3 Hobbies and recreation              13     7    -6    13\n4 Physical and mental health          13     9    -4    13\n5 COVID-19                             8     5    -3     8\n6 Pets                                 5     2    -3     5\n7 Nature and the outdoors              5     3    -2     5\n\ndf_long %&gt;% head()\n\n# A tibble: 6 × 5\n  labels                             gap   max name  value\n  &lt;fct&gt;                            &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1 Spirituality, faith and religion    14    22 Dem       8\n2 Spirituality, faith and religion    14    22 Rep      22\n3 Freedom and independence             6    12 Dem       6\n4 Freedom and independence             6    12 Rep      12\n5 Hobbies and recreation              -6    13 Dem      13\n6 Hobbies and recreation              -6    13 Rep       7\n\n\n\n\nPlot\n\n# set a custom nudge value\nnudge_value=.6\n\np_main=\ndf_long %&gt;% \n  \n  # the following 3 lines of code are the same\n  ggplot(aes(x=value,y=labels)) +\n  geom_line(aes(group=labels), color=\"#E7E7E7\", linewidth=3.5) +\n  geom_point(aes(color=name), size=3) +\n  \n  # but we want geom_text for the data callouts and the legend\n  \n  # data callout\n  geom_text(aes(label=value, color=name),\n            size=3.25,\n            nudge_x=if_else(\n              df_long$value==df_long$max, # if it's the larger value...\n              nudge_value,   # move it to the right of the point\n              -nudge_value), # otherwise, move it to the left of the point\n            hjust=if_else(\n              df_long$value==df_long$max, #if it's the larger value\n              0, # left justify\n              1),# otherwise, right justify      \n            )+\n   \n  # legend\n  geom_text(aes(label=name, color=name), \n            data=. %&gt;% filter(gap==max(gap)),\n            nudge_y =.5, \n            fontface=\"bold\",\n            size=3.25)+  \n  \n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.y = element_text(color=\"black\"),\n        axis.text.x = element_text(color=\"#989898\"),\n        axis.title = element_blank(),\n        panel.grid = element_blank()\n        ) +\n  labs(x=\"%\",y=NULL) +\n  scale_color_manual(values=c(\"#436685\", \"#BF2F24\")) +\n  \n  #extend the y-axis otherwise the legend is cut off\n  coord_cartesian(ylim=c(1, 7.5)) +\n  \n  #display percentages with % appended\n  scale_x_continuous(labels = scales::percent_format(scale = 1)) \n\np_main"
  },
  {
    "objectID": "posts/dumbbell-with-gap/dumbbell.html#gap-figure",
    "href": "posts/dumbbell-with-gap/dumbbell.html#gap-figure",
    "title": "Tutorial: Dumbbell Chart with a Gap Column",
    "section": "Gap Figure",
    "text": "Gap Figure\nPew formats the gap values in a particular way:\n\nColors by party\nAdds “+” to the beginning of the gap value if positive\nAdds “R” or “D” to the end of the gap value\n\nLet’s do that!\n\nData Wrangle\n\ndf_gap=\ndf %&gt;%  # note i am using df and not df_long\n  mutate(\n    label=fct_reorder(labels, abs(gap)), #order label by descending gaps\n    \n    # we need a column for the party with the max value\n    gap_party_max=if_else(\n      Rep==max, \n      \"R\",\n      \"D\"\n    ),\n    \n    # format gap values\n    gap_label=\n      paste0(\"+\", abs(gap), gap_party_max) %&gt;% \n      fct_inorder() #turns into factor to bake in the order\n  )\n\ndf_gap\n\n# A tibble: 7 × 8\n  labels                     Dem   Rep   gap   max label gap_party_max gap_label\n  &lt;fct&gt;                    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;chr&gt;         &lt;fct&gt;    \n1 Spirituality, faith and…     8    22    14    22 Spir… R             +14R     \n2 Freedom and independence     6    12     6    12 Free… R             +6R      \n3 Hobbies and recreation      13     7    -6    13 Hobb… D             +6D      \n4 Physical and mental hea…    13     9    -4    13 Phys… D             +4D      \n5 COVID-19                     8     5    -3     8 COVI… D             +3D      \n6 Pets                         5     2    -3     5 Pets  D             +3D      \n7 Nature and the outdoors      5     3    -2     5 Natu… D             +2D      \n\n\n\n\nPlot\n\np_gap=\n  df_gap %&gt;% \n  ggplot(aes(x=gap,y=labels)) +\n  geom_text(aes(x=0, label=gap_label, color=gap_party_max),\n            fontface=\"bold\",\n            size=3.25) +\n  \n  geom_text(aes(x=0, y=7), # 7 because that's the # of y-axis values\n            label=\"Diff\",\n            nudge_y =.5, # match the nudge value of the main plot legend    \n            fontface=\"bold\",\n            size=3.25) +\n  \n  theme_void() +\n  coord_cartesian(xlim = c(-.05, 0.05), \n                  ylim=c(1,7.5) # needs to match main plot\n                  )+\n  theme(\n    plot.margin = margin(l=0, r=0, b=0, t=0), #otherwise it adds too much space\n    panel.background = element_rect(fill=\"#EFEFE3\", color=\"#EFEFE3\"),\n    legend.position = \"none\"\n  )+\n  scale_color_manual(values=c(\"#436685\", \"#BF2F24\"))\n\np_gap"
  },
  {
    "objectID": "posts/dumbbell-with-gap/dumbbell.html#combine-figures",
    "href": "posts/dumbbell-with-gap/dumbbell.html#combine-figures",
    "title": "Tutorial: Dumbbell Chart with a Gap Column",
    "section": "Combine Figures",
    "text": "Combine Figures\nUse the package patchwork to put together your final figure. You’ll need to play around with plot_layout() a bit to get your figures to fit together how you want.\n\np_whole=\n  # syntax from `patchwork`\n  p_main + p_gap + plot_layout(design=\n  c(\n    area(l=0,  r=45, t=0, b=1), # defines the main figure area\n    area(l=46, r=52, t=0, b=1)  # defines the gap figure area\n  )) \n\np_whole"
  },
  {
    "objectID": "posts/free-speech/free-speech.html#objective",
    "href": "posts/free-speech/free-speech.html#objective",
    "title": "Research: Free Speech and Inclusion",
    "section": "Objective",
    "text": "Objective\nThe objective of this study was to explore the current climate of free speech and inclusion within higher education institutions, particularly how college students navigate and perceive the dynamics of speech and ideological expression on campuses across the United States."
  },
  {
    "objectID": "posts/free-speech/free-speech.html#approach",
    "href": "posts/free-speech/free-speech.html#approach",
    "title": "Research: Free Speech and Inclusion",
    "section": "Approach",
    "text": "Approach\n\nResearch Design: As a research fellow at More in Common, I was a key contributer to a comprehensive survey that aimed to capture a wide array of viewpoints on the topic of free speech and social inclusion.\nSurvey Execution: We partnered with the nonprofit Constructive Dialogue Institute to develop and administer a national survey to 2,618 college students, using Qualtrics Panels for its robust sampling and the Qualtrics platform for its survey programming.\nData Collection: The survey included a variety of questions designed to measure students’ attitudes towards free speech, “cancel culture,” and their personal experiences with speech on campus. This included demographic data to ensure broad representation across different regions and institution types."
  },
  {
    "objectID": "posts/free-speech/free-speech.html#analysis-and-findings",
    "href": "posts/free-speech/free-speech.html#analysis-and-findings",
    "title": "Research: Free Speech and Inclusion",
    "section": "Analysis and Findings",
    "text": "Analysis and Findings\n\nStatistical Analysis: Used statistical methods to analyze the data, focusing on frequences and correlates of students’ political ideologies, experiences of being offended, and their tendencies to engage in or be subjected to call out behaviors.\nExploratory Data Analysis: In the report, we presented quantitative findings in a format simplified for the general public. However, behind the scenes, I conducted in-depth statistical analyses to ensure the robustness of our results. Below is a selection of data visualizations from this extensive analysis. These samples from my exploratory data analysis investigate how beliefs in social justice, termed “Social Justice Orientation” (SJO), relate to other variables."
  },
  {
    "objectID": "posts/free-speech/free-speech.html#tools-used",
    "href": "posts/free-speech/free-speech.html#tools-used",
    "title": "Research: Free Speech and Inclusion",
    "section": "Tools Used",
    "text": "Tools Used\n\nQualtrics: Used for survey programming due to its best-in-class survey platform.\nStatistical Software: Analysis was conducted using R, which facilitated rigorous examination of the data to identify trends and draw meaningful conclusions.\nTeam Coordination Tools: Leveraged project management and communication tools (Asana, Slack) to coordinate research activities among team members spread across organizations and geographic locations."
  },
  {
    "objectID": "posts/free-speech/free-speech.html#outputs",
    "href": "posts/free-speech/free-speech.html#outputs",
    "title": "Research: Free Speech and Inclusion",
    "section": "Outputs",
    "text": "Outputs\n\nRead the full report\nRead a More in Common newsletter summary of the report"
  },
  {
    "objectID": "posts/multiracial-usa/multiracial-usa.html#objective",
    "href": "posts/multiracial-usa/multiracial-usa.html#objective",
    "title": "Multiracial Counties in the US",
    "section": "Objective",
    "text": "Objective\nTo visualize and compare the distribution of multiracial populations across U.S. counties, highlighting areas with higher than the national average (2.6%) per capita of multiracial individuals."
  },
  {
    "objectID": "posts/multiracial-usa/multiracial-usa.html#approach",
    "href": "posts/multiracial-usa/multiracial-usa.html#approach",
    "title": "Multiracial Counties in the US",
    "section": "Approach",
    "text": "Approach\nCreated a map to display multiracial population data by county. Counties in blue show a have a higher than national average proportion of multiracial individuals. The map also identifies specific counties with the lowest and highest multiracial populations."
  },
  {
    "objectID": "posts/multiracial-usa/multiracial-usa.html#tools-used",
    "href": "posts/multiracial-usa/multiracial-usa.html#tools-used",
    "title": "Multiracial Counties in the US",
    "section": "Tools Used",
    "text": "Tools Used\nData was acquired using the tidycensus package in R, allowing access to detailed census data. The visualization was constructed using GIS software capabilities within R, using ggplot2 for map rendering and aesthetic adjustments. Data callouts were added with Adobe Photoshop."
  },
  {
    "objectID": "posts/redemption-poster/redemption-poster.html#objective",
    "href": "posts/redemption-poster/redemption-poster.html#objective",
    "title": "Dataviz: “A Recipe for Redemption” Research Poster",
    "section": "Objective",
    "text": "Objective\nPresent the findings from a comprehensive six-study research project on moral redemption through a detailed and engaging 48” x 36” poster at the Morality Preconference for the 2024 Annual Conference of the Society for Personality and Social Psychology."
  },
  {
    "objectID": "posts/redemption-poster/redemption-poster.html#approach",
    "href": "posts/redemption-poster/redemption-poster.html#approach",
    "title": "Dataviz: “A Recipe for Redemption” Research Poster",
    "section": "Approach",
    "text": "Approach\nMost research posters are three-columns. I adopted an unique five-column layout inspired by the design of newspapers to manage the extensive data from multiple studies effectively. This layout facilitated structured storytelling and highlighted key findings—organized by two overarching research questions—across the broader themes of the research, enhancing viewer engagement and understanding."
  },
  {
    "objectID": "posts/redemption-poster/redemption-poster.html#tools",
    "href": "posts/redemption-poster/redemption-poster.html#tools",
    "title": "Dataviz: “A Recipe for Redemption” Research Poster",
    "section": "Tools",
    "text": "Tools\nUsed R for data analysis and visualizations. Utilized PowerPoint for the final poster design, focusing on creating a visually appealing and informative presentation that balances text content with visual data representation."
  }
]